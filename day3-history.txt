ls -la
sudo kubeadm config print
sudo kubeadm config print init-defaults 
kubectl get pods
kubectl get svc
vi test-dns.yaml
kubectl apply -f test-dns.yaml
kubectl get pods
kubectl exec -it test-dns -- bash
kubectl exec -it test-dns -- sh
kubectl apply -f test-dns.yaml -n app1
kubectl -n app1 exec -it test-dns -- sh
kubectl get pods -o wide
kubectl -n app1 exec -it test-dns -- sh
cd ../day3/
kubectl run nodename-pod --image nginx --dry-run=client -o yaml > nodename-pod.yml
mv nodename-pod.yml nodename-pod.yaml
vi nodename-pod.yaml
kubectl get pods -o wide | grep worker01 | wc -l
kubectl get pods -o wide | grep worker02 | wc -l
vi nodename-pod.yaml 
kubectl apply -f nodename-pod.yaml
kubectl get pods -o wide
cp -rp nodename-pod.yaml nodeselector-pod.yaml
vi nodeselector-pod.yaml
kubectl get node worker02 --show-labels 
kubectl label nodes worker01 kubernetes.io/env=prod
kubectl label nodes worker02 kubernetes.io/env=dev
kubectl get nodes --show-labels 
vi nodeselector-pod.yaml
kubectl apply -f nodeselector-pod.yaml
kubectl get pods -o wide
kubectl events
kubectl label node worker02 kubernetes.io/env=test
kubectl label node worker02 kubernetes.io/env=test --overwrite
kubectl get pods -o wide
kubectl get pods -o wide | grep worker02 | wc -l
kubectl get pods -o wide | grep worker01 | wc -l
kubectl get nodes
kubectl describe nodes worker01
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
sudo apt  install jq -y
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
kubectl taint node worker01 zone=secure:NoSchedule
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
kubectl run test-taint-pod --iimage nginx --dry-run=client -o yaml > test-taint-pod.yaml
kubectl run test-taint-pod --image nginx --dry-run=client -o yaml > test-taint-pod.yaml
vi test-taint-pod.yaml
kubectl apply -f test-taint-pod.yaml
kubectl get pods -o wide
cp test-taint-pod.yaml test-taint-pod2.yaml
vi test-taint-pod2.yaml
kubectl apply -f test-taint-pod2.yaml
kubectl get pods -o wide
cp -rp test-taint-pod2.yaml test-toleration-pod.yaml
vi test-toleration-pod.yaml
kubectl taint node worker02 zone=insecure:NoExecute ; watch -n1 kubectl get pods -o wide
kubectl taint node worker02 zone=insecure:NoExecute-
kubectl get pods -o wide
kubectl apply -f test-toleration-pod.yaml 
kubectl get pods -o wide
vi test-toleration-pod.yaml 
kubectl apply -f test-toleration-pod.yaml
kubectl get pods -o wide
kubectl taint node worker02 zone=insecure:NoExecute ; watch -n1 kubectl get pods -o wide
kubectl edit deployments.apps my-deployment 
kubectl get pods -o wide
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
kubectl taint node worker01 zone=secure:NoSchedule-
kubectl taint node worker02 zone=insecure:NoExecute-
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
kubectl get pods -o wide
kubectl get pods -o wide | grep worker01 | wc -l
kubectl get pods -o wide | grep worker02 | wc -l
kubectl rollout restart deployment my-deployment 
kubectl get pods -o wide
kubectl get pods -o wide | grep worker02 | wc -l
kubectl get pods -o wide | grep worker01 | wc -l
kubectl delete pod my-replicaset-56rhx my-replicaset-592hc 
kubectl get pods -o wide | grep worker01 | wc -l
kubectl get pods -o wide | grep worker02 | wc -l
kubectl get nodes --show-labels 
kubectl label node worker01 kubernetes.io/country=poland
kubectl label node worker02 kubernetes.io/country=france
kubectl get nodes --show-labels 
vi with-node-affinity.yaml
kubectl apply -f with-node-affinity.yaml
kubectl get pods -o wide
vi with-pod-affinity.yaml
kubectl get pods --show-labels 
vi with-node-affinity.yaml 
vi with-pod-affinity.yaml
kubectl get pods --show-labels 
kubectl apply -f with-node-affinity.yaml 
kubectl get pods --show-labels 
vi with-pod-affinity.yaml
kubectl apply -f with-pod-affinity.yaml
kubectl get pods -o wide
cp -rp with-pod-affinity.yaml with-pod-antiaffinity.yaml
vi with-pod-antiaffinity.yaml
kubectl apply -f with-pod-antiaffinity.yaml
kubectl get pods -o wide
history
history| awk '$1 > 335' | cut -c 8- >> ../day3-history.txt
ls -la
sudo kubeadm config print
sudo kubeadm config print init-defaults 
kubectl get pods
kubectl get svc
vi test-dns.yaml
kubectl apply -f test-dns.yaml
kubectl get pods
kubectl exec -it test-dns -- bash
kubectl exec -it test-dns -- sh
kubectl apply -f test-dns.yaml -n app1
kubectl -n app1 exec -it test-dns -- sh
kubectl get pods -o wide
kubectl -n app1 exec -it test-dns -- sh
cd ../day3/
kubectl run nodename-pod --image nginx --dry-run=client -o yaml > nodename-pod.yml
mv nodename-pod.yml nodename-pod.yaml
vi nodename-pod.yaml
kubectl get pods -o wide | grep worker01 | wc -l
kubectl get pods -o wide | grep worker02 | wc -l
vi nodename-pod.yaml 
kubectl apply -f nodename-pod.yaml
kubectl get pods -o wide
cp -rp nodename-pod.yaml nodeselector-pod.yaml
vi nodeselector-pod.yaml
kubectl get node worker02 --show-labels 
kubectl label nodes worker01 kubernetes.io/env=prod
kubectl label nodes worker02 kubernetes.io/env=dev
kubectl get nodes --show-labels 
vi nodeselector-pod.yaml
kubectl apply -f nodeselector-pod.yaml
kubectl get pods -o wide
kubectl events
kubectl label node worker02 kubernetes.io/env=test
kubectl label node worker02 kubernetes.io/env=test --overwrite
kubectl get pods -o wide
kubectl get pods -o wide | grep worker02 | wc -l
kubectl get pods -o wide | grep worker01 | wc -l
kubectl get nodes
kubectl describe nodes worker01
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
sudo apt  install jq -y
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
kubectl taint node worker01 zone=secure:NoSchedule
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
kubectl run test-taint-pod --iimage nginx --dry-run=client -o yaml > test-taint-pod.yaml
kubectl run test-taint-pod --image nginx --dry-run=client -o yaml > test-taint-pod.yaml
vi test-taint-pod.yaml
kubectl apply -f test-taint-pod.yaml
kubectl get pods -o wide
cp test-taint-pod.yaml test-taint-pod2.yaml
vi test-taint-pod2.yaml
kubectl apply -f test-taint-pod2.yaml
kubectl get pods -o wide
cp -rp test-taint-pod2.yaml test-toleration-pod.yaml
vi test-toleration-pod.yaml
kubectl taint node worker02 zone=insecure:NoExecute ; watch -n1 kubectl get pods -o wide
kubectl taint node worker02 zone=insecure:NoExecute-
kubectl get pods -o wide
kubectl apply -f test-toleration-pod.yaml 
kubectl get pods -o wide
vi test-toleration-pod.yaml 
kubectl apply -f test-toleration-pod.yaml
kubectl get pods -o wide
kubectl taint node worker02 zone=insecure:NoExecute ; watch -n1 kubectl get pods -o wide
kubectl edit deployments.apps my-deployment 
kubectl get pods -o wide
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
kubectl taint node worker01 zone=secure:NoSchedule-
kubectl taint node worker02 zone=insecure:NoExecute-
kubectl get nodes -o json | jq -r '.items[] | "Node name: \(.metadata.name), Taints: \(.spec.taints[0])"' 
kubectl get pods -o wide
kubectl get pods -o wide | grep worker01 | wc -l
kubectl get pods -o wide | grep worker02 | wc -l
kubectl rollout restart deployment my-deployment 
kubectl get pods -o wide
kubectl get pods -o wide | grep worker02 | wc -l
kubectl get pods -o wide | grep worker01 | wc -l
kubectl delete pod my-replicaset-56rhx my-replicaset-592hc 
kubectl get pods -o wide | grep worker01 | wc -l
kubectl get pods -o wide | grep worker02 | wc -l
kubectl get nodes --show-labels 
kubectl label node worker01 kubernetes.io/country=poland
kubectl label node worker02 kubernetes.io/country=france
kubectl get nodes --show-labels 
vi with-node-affinity.yaml
kubectl apply -f with-node-affinity.yaml
kubectl get pods -o wide
vi with-pod-affinity.yaml
kubectl get pods --show-labels 
vi with-node-affinity.yaml 
vi with-pod-affinity.yaml
kubectl get pods --show-labels 
kubectl apply -f with-node-affinity.yaml 
kubectl get pods --show-labels 
vi with-pod-affinity.yaml
kubectl apply -f with-pod-affinity.yaml
kubectl get pods -o wide
cp -rp with-pod-affinity.yaml with-pod-antiaffinity.yaml
vi with-pod-antiaffinity.yaml
kubectl apply -f with-pod-antiaffinity.yaml
kubectl get pods -o wide
history
history| awk '$1 > 335' | cut -c 8- >> ../day3-history.txt
git status
kubectl api-versions | grep cron
kubectl api-versions | grep -i cron
kubectl api-versions | grep batch
kubectl api-versions | grep batch -o
kubectl api-versions | grep batch -i
kubectl api-versions 
kubectl api-resources | grep -i cron
kubectl api-resources | grep -i job
vi job-pi.yaml
kubectl apply -f job-pi.yaml
watch -n1 kubectl get jobs
kubectl get pods
kubectl logs job-pi-qzv2w 
vi my-job.yaml
cp -rp job-pi.yaml my-job.yaml 
vi my-job.yaml
kubectl apply -f my-job.yaml
watch -n1 kubectl get jobs
kubectl get pods
watch -n1 kubectl get jobs
kubectl get pods
vi hello-cronjob.yaml
kubectl apply -f hello-cronjob.yaml
kubectl get cj
watch -n1 kubectl get cj,jobs,pod
kubectl logs jobs/hello-cronjob-28789054
kubectl logs jobs/hello-cronjob-28789053
kubectl get pods
kubectl delete cj hello-cronjob 
kubectl get pods
kubectl expose pod alpine --name test-svc --port 80 --dry-run-client -i yaml
kubectl expose pod alpine --name test-svc --port 80 --dry-run=client -i yaml
kubectl expose pod alpine --name test-svc --port 80 --dry-run=client -o yaml
kubectl expose pod test-dns --name test-svc --port 80 --dry-run=client -o yaml
vi web-sts.yaml
kubectl apply -f web-sts.yaml
kubectl get sts
kubectl get pods
watch -n1 kubectl get pods
watch -n1 kubectl get pods,sts
watch -n1 kubectl get pods,sts,svc
sudo apt-get install yamllint
yamllint --help
yamllint with-pod-affinity.yaml 
vi web-sts.yaml 
vi web-sts.yaml --format
vi web-sts.yaml --format parsable
yamllint --format auto web-sts.yaml 
vi web-sts.yaml 
yamllint --format auto web-sts.yaml 
yamllint --format auto web-sts.yaml --no-warnings
kubectl api-resources | grep -i job
kubectl get pods
kubectl delete all --all
ls -la
rm '\'
kubectl get pods
kubectl create 
kubectl create deploy nginx --image nginx 
kubectl get pods
index.html
vi index.html
kubectl cp index.html nginx-bf5d5cf98-lt26m:/usr/share/nginx/html/index.html
kubectl get pods
kubectl get pods -o wide
kubectl expose deployment nginx --name nginx-svc --type NodePort --port 80
kubectl get svc
kubectl rollout restart deployment nginx 
kubectl get svc
kubectl get pods -o wide
kubectl create deploy nginx --image nginx --dry-run=client -o yaml > nginx-volume-pod.yaml
vi nginx-volume-pod.yaml
kubectl apply -f nginx-volume-pod.yaml
vi nginx-volume-pod.yaml
kubectl delete deployments.apps nginx 
kubectl apply -f nginx-volume-pod.yaml
kubectl get pods -o wide
kubectl exec -it nginx-web-f6c8bc8fd-zcfl6 -- bash
scp index.html student@192.168.1.120:/tmp/
kubectl expose deployment nginx-web --name nginx-web-svc --type NodePort --port 80
kubectl get svc
kubectl delete pod nginx-web-f6c8bc8fd-zcfl6 
kubectl get pods -o wide
kubectl edit deployments.apps nginx-web 
kubectl get pods -o wide
sudo apt install nfs-common nfs-kernel-server cifs-utils -y
mkdir /var/nfs
sudo mkdir /var/nfs
sudo chmod 777 /var/nfs
sudo vi /etc/exports 
sudo exportfs -rav
cp -rp nginx-volume-pod.yaml nginx-nfs-volume-pod.yaml
vi nginx-nfs-volume-pod.yaml
kubectl apply -f nginx-nfs-volume-pod.yaml
kubectl expose deployment nginx-nfs-volume-pod --type NodePort --name nfs-svc --port 80
kubectl get svc
kubectl get deplo,pod
kubectl get deploy,pod
kubectl events
kubectl events -f
kubectl events -w
kubectl get deploy,pod
kubectl get svc
ls -la /var/nfs
echo "<html><body><h1>NFS WEBSITE</h1></body></html>" > /var/nfs/index.html
ls -la /var/nfs/index.html
sudo chmod 777 -R /var/nfs/
ls -la /var/nfs/index.html
vi nginx-nfs-volume-pod.yaml
kubectl get storageclasses.storage.k8s.io 
vi nfs-pv.yaml
vi nginx-nfs-volume-pod.yaml
vi nfs-pv.yaml
kubectl apply -f nfs-pv.yaml
kubectl get pv
vi nfs-pvc.yaml
kubectl apply -f nfs-pvc.yaml
kubectl get pv,pvc
kubectl edit pvc
vi nfs-pvc.yaml 
kubectl get pods
kubectl get pv,pvc
kubectl replace --force -f nfs-pvc.yaml
kubectl get pv,pvc
vi nfs-pod.yaml
kubectl apply -f nfs-pod.yaml
kubectl get pod
vi nfs-pod.yaml
kubectl edit pod nfs-pod 
kubectl expose pod nfs-pod --name nfs-svc-pod --port 80 --type NodePort
kubectl get svc
git clone https://github.com/kubernetes-sigs/nfs-ganesha-server-and-external-provisioner.git
cd nfs-ganesha-server-and-external-provisioner/
kubectl create -f deploy/kubernetes/deployment.yaml
kubectl create -f deploy/kubernetes/rbac.yaml
vi deploy/kubernetes/class.yaml
kubectl apply -f deploy/kubernetes/class.yaml
kubectl describe sc nfs-class 
kubectl get sc
vi test-pvc.yaml
vi dynamic-pvc.yaml
cd ..
mv nfs-ganesha-server-and-external-provisioner/dynamic-pvc.yaml .
kubectl apply -f dynamic-pvc.yaml
kubectl get pv,pvc
kubectl delete pvc dynamic-pvc 
kubectl get pv,pvc
kubectl delete pvc nfs-pvc
kubectl describe pod | grep nfs-pvc
kubectl get pv,pvc
kubectl edit pvc nfs-pvc 
kubectl get pv,pvc
kubectl describe pod | grep nfs-pvc
kubectl delete pod nfs-pod 
kubectl describe pod | grep nfs-pvc
kubectl apply -f nfs-pvc.yaml 
kubectl get pv,pvc
kubectl get pv nfs-pv -o yaml
kubectl patch pv nfs-pv -p '{"spec":{"claimRef":null}}'
kubectl get pv,pvc
vi my-configmap.yaml
kubectl apply -f my-configmap.yaml
kubectl get cm
kubectl describe cm my-configmap 
vi env-file
cp env-file normal-file
kubectl create cm map1 --from-file normal-file 
kubectl create cm from-env-file --from-env-file env-file 
kubectl describe map1
kubectl describe cm map1
kubectl describe cm from-env-file 
kubectl create cm map2 --from-literal productVersion=1.0 --from-literal zone=secure --from-file env-file 
kubectl describe cm map2
vi configmap-pod.yaml
kubectl apply -f configmap-pod.yaml
kubectl exec -it configmap-pod -- env
vi configmap-volume-pod.yaml
kubectl apply -f configmap-volume-pod.yaml
kubectl exec -it configmap-volume-pod -- bash
kubectl exec -it configmap-volume-pod -- sh
kubectl edit cm my-configmap 
kubectl exec -it configmap-volume-pod -- sh
vi root_mariadb
kubectl create secret generic db-pass --from-file root_mariadb 
kubectl get secret
kubectl get secret -o yaml
echo "U2VjdXJlUGFzczEyMwo=" | base64 -d ; echo 
htpasswd -c .htpasswd mariola
sudo apt install apache2-utils -y
htpasswd -c .htpasswd mariola
cat .htpasswd 
kubectl create secret generic nginx-htpasswd --from-file .htpasswd 
rm .htpasswd 
kubectl describe secrets nginx-htpasswd 
vi nginx-config.yaml
kubectl apply -f nginx-config.yaml
vi nginx-pod.yaml
kubectl apply -f nginx-pod.yaml
kubectl get pod --show-labels 
kubectl edit pod nginx-pod 
kubectl expose pod nginx-pod --name secure-svc --port 80 --type NodePort
kubectl get pods
kubectl get svc
vi flask-app.yaml
kubectl get ns
vi flask-app.yaml
kubectl get svc secure-svc -o yaml
vi flask-app.yaml
kubectl get svc
kubectl apply -f flask-app.yaml
watch -n1 kubectl get all -n app
kubectl edit deployments.apps -n app flask 
watch -n1 kubectl get all -n app
history| awk '$1 > 335' | cut -c 8- >> ../day3-history.txt
